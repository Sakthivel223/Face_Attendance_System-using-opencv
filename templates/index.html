<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Recognition System</title>
    <link rel="icon" href="static/icons/favicon_ico/favicon-32x32.png" type="image/png">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        :root {
            --primary-color: #1a3a5f;
            --secondary-color: #2980b9;
            --success-color: #27ae60;
            --danger-color: #c0392b;
            --light-color: #ecf0f1;
            --dark-color: #2c3e50;
            --border-radius: 8px;
            --box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background-color: #f8f9fa;
            color: #333;
            line-height: 1.6;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        header {
            background: linear-gradient(135deg, var(--primary-color), var(--dark-color));
            color: white;
            padding: 25px 0;
            text-align: center;
            box-shadow: var(--box-shadow);
        }
        
        .main-title {
            font-size: 2.2rem;
            margin-bottom: 10px;
            font-weight: 600;
        }
        
        .sub-title {
            font-size: 1.2rem;
            font-weight: normal;
            opacity: 0.9;
        }
        
        .content {
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 30px 0;
        }
        
        .video-container {
            position: relative; 
            width: 100%;
            max-width: 800px;
            height: 600px;
            margin: 20px 0;
            background-color: #000;
            border-radius: var(--border-radius);
            overflow: hidden;
            box-shadow: var(--box-shadow);
            position: relative;
            border: 1px solid rgba(0,0,0,0.1);
        }
        
        .video-feed {
            width: 100%;
            height: 100%;
            object-fit: cover;
            position: absolute;
            top: 0;
            left: 0;
            z-index: 1; /* Ensure the video is behind the image initially */
        }
        .video-placeholder {
            width: 100%;
            height: 100%;
            object-fit: cover;
            position: absolute; /* Places the image over the video */
            top: 0;
            left: 0;
            display: block; /* Ensure it's visible initially */
            z-index: 2; /* Ensure the placeholder is always on top */
            background-color: #000; /* Prevents a transparent gap */
        }
        .panel {
            background-color: white;
            padding: 25px;
            border-radius: var(--border-radius);
            box-shadow: var(--box-shadow);
            margin: 20px 0;
            width: 100%;
            max-width: 800px;
            border: 1px solid rgba(0,0,0,0.05);
            transition: transform 0.3s ease;
        }
        
        .panel:hover {
            transform: translateY(-5px);
        }
        
        .panel h2 {
            color: var(--primary-color);
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 10px;
            font-weight: 600;
        }
        
        .status-active {
            color: var(--success-color);
            font-weight: bold;
            display: inline-flex;
            align-items: center;
        }
        
        .status-active::before {
            content: '';
            display: inline-block;
            width: 10px;
            height: 10px;
            background-color: var(--success-color);
            border-radius: 50%;
            margin-right: 5px;
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 0.6; }
            50% { opacity: 1; }
            100% { opacity: 0.6; }
        }
        
        .status-inactive {
            color: var(--danger-color);
            font-weight: bold;
        }
        
        .button-panel {
            display: flex;
            gap: 15px;
            margin: 25px 0;
            flex-wrap: wrap;
            justify-content: center;
        }
        
        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: var(--border-radius);
            cursor: pointer;
            font-size: 1rem;
            font-weight: 600;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 10px;
            box-shadow: var(--box-shadow);
        }
        
        .btn-primary {
            background-color: var(--secondary-color);
            color: white;
        }
        
        .btn-success {
            background-color: var(--success-color);
            color: white;
        }
        
        .btn-danger {
            background-color: var(--danger-color);
            color: white;
        }
        
        .btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 6px 12px rgba(0,0,0,0.15);
        }
        
        .btn:active {
            transform: translateY(-1px);
        }
        
        .btn:disabled {
            opacity: 0.7;
            cursor: not-allowed;
        }
        
        footer {
            background: linear-gradient(135deg, var(--dark-color), var(--primary-color));
            color: white;
            text-align: center;
            padding: 25px 0;
            margin-top: 40px;
        }
        
        .loading-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0,0,0,0.7);
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
            color: white;
            z-index: 100;
            display: none;
        }
        
        .spinner {
            border: 5px solid rgba(255,255,255,0.3);
            border-radius: 50%;
            border-top: 5px solid var(--secondary-color);
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
            margin-bottom: 20px;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .toast {
            position: fixed;
            top: 20px;
            right: 20px;
            background-color: white;
            color: #333;
            padding: 15px 20px;
            border-radius: var(--border-radius);
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
            z-index: 1000;
            transform: translateX(150%);
            transition: transform 0.3s ease;
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .toast.success {
            border-left: 4px solid var(--success-color);
        }
        
        .toast.success::before {
            content: '\f058';
            font-family: 'Font Awesome 5 Free';
            font-weight: 900;
            color: var(--success-color);
        }
        
        .toast.error {
            border-left: 4px solid var(--danger-color);
        }
        
        .toast.error::before {
            content: '\f057';
            font-family: 'Font Awesome 5 Free';
            font-weight: 900;
            color: var(--danger-color);
        }
        
        .toast.info {
            border-left: 4px solid var(--secondary-color);
        }
        
        .toast.info::before {
            content: '\f05a';
            font-family: 'Font Awesome 5 Free';
            font-weight: 900;
            color: var(--secondary-color);
        }
        
        .toast.show {
            transform: translateX(0);
        }
        
        .stats-panel {
            background-color: white;
            padding: 25px;
            border-radius: var(--border-radius);
            box-shadow: var(--box-shadow);
            margin: 20px 0;
            width: 100%;
            max-width: 800px;
            border: 1px solid rgba(0,0,0,0.05);
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 20px;
        }
        
        .stat-card {
            background: linear-gradient(145deg, #f8f9fa, #e9ecef);
            padding: 20px;
            border-radius: var(--border-radius);
            text-align: center;
            box-shadow: 0 2px 5px rgba(0,0,0,0.05);
            transition: transform 0.3s ease;
            border: 1px solid rgba(0,0,0,0.05);
        }
        
        .stat-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        
        .stat-value {
            font-size: 2rem;
            font-weight: bold;
            color: var(--primary-color);
            margin-bottom: 5px;
        }
        
        .stat-label {
            font-size: 0.9rem;
            color: var(--dark-color);
            font-weight: 500;
        }
        
        .stat-icon {
            font-size: 1.5rem;
            color: var(--secondary-color);
            margin-bottom: 10px;
        }
        
        /* Media Queries for Responsive Design */
        @media (max-width: 992px) {
            .container {
                padding: 15px;
            }
            
            .video-container {
                height: 500px;
            }
            
            .main-title {
                font-size: 1.8rem;
            }
            
            .sub-title {
                font-size: 1.1rem;
            }
        }
        
        @media (max-width: 768px) {
            .video-container {
                height: 400px;
            }
            
            .stats-grid {
                grid-template-columns: repeat(2, 1fr);
            }
            
            .button-panel {
                flex-direction: column;
                width: 100%;
                max-width: 300px;
            }
            
            .btn {
                width: 100%;
                justify-content: center;
            }
        }
        
        @media (max-width: 576px) {
            .video-container {
                height: 300px;
            }
            
            .main-title {
                font-size: 1.5rem;
            }
            
            .sub-title {
                font-size: 1rem;
            }
            
            .stats-grid {
                grid-template-columns: 1fr;
            }
            
            .panel, .stats-panel {
                padding: 15px;
            }
            
            .toast {
                width: 90%;
                left: 5%;
                right: 5%;
            }
        }
    </style>
</head>
<body>
    <header>
        <div class="container">
            <h1 class="main-title">Face Recognition System</h1>
            <p class="sub-title">Secure Access Control & Attendance Management</p>
        </div>
    </header>
    
    <div class="container content">
        <div class="video-container">
            <video id="videoFeed" class="video-feed" autoplay playsinline></video>
<img src="/static/icons/placeholder.webp" alt="Video Placeholder" class="video-placeholder" style="width: 100%; height: 100%; object-fit: cover; display: block;" />


            <div class="loading-overlay" id="loadingOverlay">
                <div class="spinner"></div>
                <p>Initializing camera...</p>
            </div>
        </div>
        
        <div class="panel">
            <h2><i class="fas fa-shield-alt"></i> System Status</h2>
            <p>Recognition Status: <span id="status" class="status-inactive">Stopped</span></p>
            <p>Camera Status: <span id="cameraStatus">Not Initialized</span></p>
            <p>Last recognition: <span id="lastRecognition">None</span></p>
        </div>
        
        <div class="button-panel">
            <button class="btn btn-success" id="startBtn" onclick="startRecognition();">

                <i class="fas fa-play"></i> Start Recognition
            </button>
            <button class="btn btn-danger" id="stopBtn" onclick="stopRecognition();">

                <i class="fas fa-stop"></i> Stop Recognition
            </button>
            <button class="btn btn-primary" onclick="window.location.href='/update'">
                <i class="fas fa-user-plus"></i> Register New Employee
            </button>
        </div>
        
        <div class="stats-panel">
            <h2><i class="fas fa-chart-line"></i> System Overview</h2>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-icon"><i class="fas fa-users"></i></div>
                    <div class="stat-value" id="totalEmployees">0</div>
                    <div class="stat-label">Registered Employees</div>
                </div>
                <div class="stat-card">
                    <div class="stat-icon"><i class="fas fa-user-check"></i></div>
                    <div class="stat-value" id="todayAttendance">0</div>
                    <div class="stat-label">Today's Attendance</div>
                </div>
                <div class="stat-card">
                    <div class="stat-icon"><i class="fas fa-clock"></i></div>
                    <div class="stat-value" id="systemUptime">0h</div>
                    <div class="stat-label">System Uptime</div>
                </div>
            </div>
        </div>
    </div>

    <div class="toast" id="toast">
        <span id="toastMessage">Message here</span>
    </div>
    
    <footer>
        <div class="container">
            <p>&copy; 2025 Face Recognition System | Secure • Reliable • Fast</p>
        </div>
    </footer>
    
    <script>
        // Global variables
        let video = document.getElementById('videoFeed');
        let isRecognitionRunning = false;
        let faceDetectionModel;
        let knownFaces = [];
        let recognitionInterval;
        let canvas;
        let attendanceData = {};
        let systemStartTime = new Date();
        let lastDetectedTime = {};
        const DETECTION_DELAY = 5000; 
        
        // DOM Elements
        const statusElement = document.getElementById('status');
        const cameraStatusElement = document.getElementById('cameraStatus');
        const lastRecognitionElement = document.getElementById('lastRecognition');
        const loadingOverlay = document.getElementById('loadingOverlay');
        const totalEmployeesElement = document.getElementById('totalEmployees');
        const todayAttendanceElement = document.getElementById('todayAttendance');
        const systemUptimeElement = document.getElementById('systemUptime');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        
        // Initialize the system
        document.addEventListener('DOMContentLoaded', async () => {
            updateSystemMetrics();
            setInterval(updateSystemMetrics, 60000); // Update metrics every minute
            
            // Create a hidden canvas for processing video frames
            canvas = document.createElement('canvas');
            canvas.width = 640;
            canvas.height = 480;
            document.body.appendChild(canvas);
            canvas.style.display = 'none';
            
            try {
                await loadKnownFaces();
                updateTotalEmployees();
                updateTodayAttendance();
                showToast('System initialized successfully', 'success');
            } catch (error) {
                console.error('Error initializing system:', error);
                showToast('Failed to initialize system', 'error');
            }
        });
        
        // Face API initialization and model loading
        async function loadFaceDetectionModel() {
            if (faceDetectionModel) return; // Already loaded
        
            showToast('Loading face detection models...', 'info');
            
            try {
                await faceapi.nets.ssdMobilenetv1.loadFromUri('/static/models');
                await faceapi.nets.faceLandmark68Net.loadFromUri('/static/models');
                await faceapi.nets.faceRecognitionNet.loadFromUri('/static/models');
                
                faceDetectionModel = true;
                showToast('Face detection models loaded successfully', 'success');
            } catch (error) {
                console.error('Error loading face detection model:', error);
                showToast('Failed to load face detection models', 'error');
                faceDetectionModel = false;
            }
        }
        
        // Load known faces from server
    async function loadKnownFaces() {
    try {
        const response = await fetch('/api/known-faces');
        
        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status}`);
        }
        
        const data = await response.json();
        
        if (!data || Object.keys(data).length === 0) {
            console.error('Known faces data is empty!');
            showToast('Warning: No known faces found in database', 'warning');
            knownFaces = [];
            return;
        }
        
        knownFaces = Object.entries(data).map(([name, descriptor]) => {
            // Validate descriptor
            if (!descriptor || !Array.isArray(descriptor) || descriptor.length === 0) {
                console.error(`Invalid descriptor for ${name}`);
                return null;
            }
            
            return {
                name,
                descriptor: new Float32Array(descriptor)
            };
        }).filter(face => face !== null); // Remove any invalid entries
        
        console.log(`Loaded ${knownFaces.length} known faces`);
        
        // Log descriptors statistics for debugging
        if (knownFaces.length > 0) {
            const sampleDescriptor = knownFaces[0].descriptor;
            console.log(`Descriptor length: ${sampleDescriptor.length}`);
            console.log(`Sample values: ${Array.from(sampleDescriptor.slice(0, 5))}`);
        }
    } catch (error) {
        console.error('Error loading known faces:', error);
        showToast('Failed to load employee data', 'error');
        knownFaces = [];
    }
}
        
        // Start the recognition process
        async function startRecognition() {
    if (isRecognitionRunning) return;
    
    loadingOverlay.style.display = 'flex';
    
    try {
        await loadFaceDetectionModel();
        
        // Start the camera with higher resolution
        const stream = await navigator.mediaDevices.getUserMedia({ 
            video: { 
                width: { ideal: 1280 },
                height: { ideal: 720 },
                facingMode: 'user',
                frameRate: { ideal: 30 } // Request higher frame rate
            } 
        });
        
        video.srcObject = stream;
        cameraStatusElement.textContent = 'Active';
        cameraStatusElement.className = 'status-active';
        
        // Wait for video to be ready
        await new Promise(resolve => {
            video.onloadedmetadata = () => {
                video.play();
                resolve();
            };
        });
        
        loadingOverlay.style.display = 'none';
        document.querySelector('.video-placeholder').style.display = 'none';
        
        // Clear any previous detected faces to start fresh
        clearDetectedFaces();
        
        // Start face recognition process
        isRecognitionRunning = true;
        statusElement.textContent = 'Running';
        statusElement.className = 'status-active';
        
        // Start the animation frame loop
        requestAnimationFrame(processVideoFrame);
        
        showToast('Face recognition started', 'success');
    } catch (error) {
        console.error('Error starting recognition:', error);
        loadingOverlay.style.display = 'none';
        showToast('Failed to start camera or recognition', 'error');
    }
}
        
        // Stop the recognition process
        function stopRecognition() {
    if (!isRecognitionRunning) return;
    
    // Just set the flag to false, the animation loop will stop on next frame
    isRecognitionRunning = false;
    
    if (video.srcObject) {
        const tracks = video.srcObject.getTracks();
        tracks.forEach(track => track.stop());
        video.srcObject = null;
    }
    
    // Remove the overlay canvas
    const videoContainer = video.parentElement;
    const overlay = videoContainer.querySelector('.face-overlay');
    if (overlay) {
        videoContainer.removeChild(overlay);
    }
    
    // Update UI
    statusElement.textContent = 'Stopped';
    statusElement.className = 'status-inactive';
    cameraStatusElement.textContent = 'Inactive';
    cameraStatusElement.className = 'status-inactive';
    
    showToast('Face recognition stopped', 'info');
    document.querySelector('.video-placeholder').style.display = 'block';
}
        
// Fix the processVideoFrame function to ensure continuous rendering
async function processVideoFrame() {
    if (!video.srcObject || !isRecognitionRunning) {
        // If not running, ensure we return immediately but maintain the loop
        if (isRecognitionRunning) {
            requestAnimationFrame(processVideoFrame);
        }
        return;
    }
    
    // Draw the current video frame to the canvas
    const context = canvas.getContext('2d', { willReadFrequently: true });
    context.drawImage(video, 0, 0, canvas.width, canvas.height);
    
    try {
        // Get the video container element
        const videoContainer = video.parentElement;
        
        // Make sure overlay exists and is properly configured
        let overlay = videoContainer.querySelector('.face-overlay');
        if (!overlay) {
            overlay = document.createElement('canvas');
            overlay.classList.add('face-overlay');
            overlay.style.position = 'absolute';
            overlay.style.top = '0';
            overlay.style.left = '0';
            overlay.style.width = '100%';
            overlay.style.height = '100%';
            overlay.style.pointerEvents = 'none';
            overlay.style.zIndex = '10';
            videoContainer.appendChild(overlay);
            console.log("Overlay created and appended to container");
        }
        
        // Always update overlay to match video dimensions exactly
        const videoRect = video.getBoundingClientRect();
        overlay.width = videoRect.width;
        overlay.height = videoRect.height;
        
        // Clear previous overlay drawing
        const overlayCtx = overlay.getContext('2d', { willReadFrequently: true });
        overlayCtx.clearRect(0, 0, overlay.width, overlay.height);
        
        // Calculate scaling between hidden canvas and displayed video dimensions
        const scaleX = videoRect.width / canvas.width;
        const scaleY = videoRect.height / canvas.height;
        
        // Detect faces in the current frame
        const detections = await faceapi.detectAllFaces(canvas)
            .withFaceLandmarks()
            .withFaceDescriptors();
        
        // Process and draw detected faces
        if (detections.length > 0) {
            // Process each detected face
            for (const detection of detections) {
                const matchResult = findBestMatch(detection.descriptor);
                const box = detection.detection.box;
                
                // Scale the box coordinates to match the displayed video size
                const boxExpansion = 0.2; // 20% larger
                const scaledBox = {
                    x: (box.x - (box.width * boxExpansion/2)) * scaleX,
                    y: (box.y - (box.height * boxExpansion/2)) * scaleY,
                    width: box.width * (1 + boxExpansion) * scaleX,
                    height: box.height * (1 + boxExpansion) * scaleY
                };
                
                // Draw face box with improved visibility
                if (matchResult.isMatch) {
                    // Known face - green box
                    drawEnhancedFaceBox(overlayCtx, scaledBox, matchResult.name, matchResult.confidence, true);
                    
                    // Handle attendance logging in the background
                    const now = Date.now();
                    if (!lastDetectedTime[matchResult.name] || now - lastDetectedTime[matchResult.name] > DETECTION_DELAY) {
                        lastDetectedTime[matchResult.name] = now;
                        setTimeout(async () => {
                            const isEntry = await logAttendance(matchResult.name);
                            if (isEntry !== null) {
                                speakGreeting(matchResult.name);
                            }
                        }, 0);
                    }
                } else {
                    // Unknown face - red box with "Unknown" label
                    drawEnhancedFaceBox(overlayCtx, scaledBox, 'Unknown', 0, false);
                    
                    setTimeout(async () => {
                        await saveUnknownFace(canvas, box, detections);
                    }, 0);
                }
            }
            
            // Update last recognition time
            lastRecognitionElement.textContent = new Date().toLocaleTimeString();
        }
        
        // Ensure overlay is always visible
        overlay.style.display = 'block';
        
    } catch (error) {
        console.error('Error in face recognition:', error);
    }
    
    // Always continue the animation loop while running
    if (isRecognitionRunning) {
        requestAnimationFrame(processVideoFrame);
    }
}

// Simplified drawing function to ensure boxes appear correctly
function drawEnhancedFaceBox(context, box, name, confidence, isKnown) {
    // Box styling parameters - IMPROVED FOR VISIBILITY
    const lineWidth = 6; // Increased from 4 to make the box much more visible
    const mainColor = isKnown ? 'rgba(39, 174, 96, 1)' : 'rgba(231, 76, 60, 1)';
    const glowColor = isKnown ? 'rgba(39, 174, 96, 0.7)' : 'rgba(231, 76, 60, 0.7)'; // Increased opacity
    const confidenceText = isKnown ? `${(confidence * 100).toFixed(1)}%` : '';
    
    // Add stronger animation effect - more vibrant pulsing 
    const pulseIntensity = Math.sin(Date.now() * 0.005) * 0.3 + 0.7; // More pronounced pulse
    
    // Reset any previous context settings
    context.setTransform(1, 0, 0, 1, 0, 0);
    context.globalAlpha = 1;
    
    // Enhanced shadow for glow effect
    context.shadowColor = glowColor;
    context.shadowBlur = 20; // Increased from 15
    context.shadowOffsetX = 0;
    context.shadowOffsetY = 0;
    
    // Draw main box with slightly rounded corners
    context.lineWidth = lineWidth;
    context.strokeStyle = mainColor;
    
    // Draw the box - use a simpler approach for better performance
    context.beginPath();
    context.rect(box.x, box.y, box.width, box.height);
    context.stroke();
    
    // Prepare for text display - make label more visible
    const fontSize = 16; // Increased from 14
    const fontFamily = "'Segoe UI', Arial, sans-serif";
    
    // Ensure the name is measured correctly for width calculation
    context.font = `bold ${fontSize}px ${fontFamily}`;
    
    // Draw a solid background rectangle for the name label
    const nameWidth = context.measureText(name).width + 20; // Extra padding
    const labelHeight = 30; // Taller label
    
    // Background for label
    context.fillStyle = mainColor;
    context.fillRect(box.x, Math.max(box.y - labelHeight - 5, 0), nameWidth, labelHeight);
    
    // Draw name text with enhanced visibility
    context.fillStyle = 'white';
    context.font = `bold ${fontSize}px ${fontFamily}`;
    context.textBaseline = 'middle';
    context.fillText(
        name, 
        box.x + 10, 
        Math.max(box.y - labelHeight/2 - 5, labelHeight/2)
    );
    
    // Draw confidence text if known face
    if (isKnown && confidenceText) {
        context.font = `${fontSize}px ${fontFamily}`;
        context.fillStyle = 'rgba(255, 255, 255, 1)'; // Fully opaque
        context.fillText(
            confidenceText, 
            box.x + nameWidth + 5, 
            Math.max(box.y - labelHeight/2 - 5, labelHeight/2)
        );
    }
}
// Global array to track detected faces during a session
let detectedFaces = [];
let simultaneousFacesDetected = false;

// Save unknown face to folder
async function saveUnknownFace(sourceCanvas, faceBox, allFacesDetected) {
    try {
        // Create a temporary canvas to hold just the face
        const tempCanvas = document.createElement('canvas');
        tempCanvas.width = faceBox.width;
        tempCanvas.height = faceBox.height;
        const tempCtx = tempCanvas.getContext('2d');
        
        // Extract face region from source canvas
        const faceRegion = sourceCanvas.getContext('2d').getImageData(
            faceBox.x, faceBox.y, faceBox.width, faceBox.height
        );
        tempCtx.putImageData(faceRegion, 0, 0);
        
        // Compute face descriptor for comparison
        const faceDescriptor = await faceapi.computeFaceDescriptor(tempCanvas);
        
        // Check if face is already in known faces database
        const matchResult = findBestMatch(faceDescriptor);
        
        // Check if multiple different faces are detected simultaneously
        if (allFacesDetected && allFacesDetected.length > 1) {
            simultaneousFacesDetected = true;
            console.log(`Multiple faces detected: ${allFacesDetected.length}`);
            
            // Log all detected faces for debugging
            console.log('All detected faces:', allFacesDetected);
        }
        
        // If it's a match with confidence above threshold, don't save as unknown
        if (matchResult.isMatch && matchResult.confidence > 0.75) {
            console.log('Face already known, not saving as unknown:', matchResult.name);
            return;
        }
        
        // Check if this face is similar to any face we've already detected in this session
        // to prevent storing the same person multiple times
        const isSimilarToDetected = isAlreadyDetected(faceDescriptor);
        
        if (isSimilarToDetected) {
            console.log('Similar face already detected in this session, not saving duplicate');
            return;
        }
        
        // Add to detected faces array to prevent future duplicates
        detectedFaces.push({
            descriptor: faceDescriptor,
            timestamp: new Date().toISOString()
        });
        
        // Create a new canvas with just the face
        const faceCanvas = document.createElement('canvas');
        faceCanvas.width = faceBox.width;
        faceCanvas.height = faceBox.height;
        const faceCtx = faceCanvas.getContext('2d');
        
        // Draw just the face region to the new canvas
        faceCtx.drawImage(
            sourceCanvas, 
            faceBox.x, faceBox.y, faceBox.width, faceBox.height,
            0, 0, faceBox.width, faceBox.height
        );
        
        // Convert to data URL
        const dataURL = faceCanvas.toDataURL('image/png');
        
        // Generate timestamp for filename
        const now = new Date();
        const timestamp = now.toISOString().replace(/[:.]/g, '-');
        
        // Add flag if multiple faces were detected
        const multiFlag = simultaneousFacesDetected ? 'multi-' : '';
        
        // Send to server for saving
        const response = await fetch('/api/save-unknown-face', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                imageData: dataURL,
                filename: `unknown-face-${multiFlag}${timestamp}.png`
            })
        });
        
        // Check if the response was successful
        if (response.ok) {
            const data = await response.json();
            console.log('Unknown face saved successfully:', data.message || 'Success');
        } else {
            const errorData = await response.json().catch(() => null);
            throw new Error(errorData?.detail || `Server error: ${response.status} ${response.statusText}`);
        }
    } catch (error) {
        console.error('Error saving unknown face:', error);
    }
}

// Helper function to determine if a face is already detected in this session
function isAlreadyDetected(newFaceDescriptor, similarityThreshold = 0.7) {
    if (!detectedFaces.length) return false;
    
    for (const storedFace of detectedFaces) {
        // Calculate similarity between face descriptors
        const distance = faceapi.euclideanDistance(newFaceDescriptor, storedFace.descriptor);
        
        // Lower distance means higher similarity
        if (distance < similarityThreshold) {
            return true;
        }
    }
    
    return false;
}

// Function to clear detected faces (can be called when starting a new session)
function clearDetectedFaces() {
    detectedFaces = [];
    simultaneousFacesDetected = false;
    console.log('Detected faces cache cleared');
}

// This function should be called from your main face detection loop
async function processDetectedFaces(video, canvas, detections) {
    // Assume detections is the array of detected faces from faceapi
    
    if (detections && detections.length > 0) {
        // Process each detected face
        for (const detection of detections) {
            const faceBox = detection.detection.box;
            // Pass all detections to saveUnknownFace to enable multi-face handling
            await saveUnknownFace(canvas, faceBox, detections);
        }
    }
    
    // Reset multi-face flag after processing is complete if needed
    // You might want different logic here based on your application needs
    // simultaneousFacesDetected = false;
}
        // Find the best match for a face descriptor
// Find the best match for a face descriptor
function findBestMatch(faceDescriptor) {
    let bestMatch = { isMatch: false, name: 'Unknown', confidence: 0 };
    const HIGH_CONFIDENCE_THRESHOLD = 0.70; // Slightly higher for better accuracy
    const MEDIUM_CONFIDENCE_THRESHOLD = 0.55; 
    
    if (!knownFaces || knownFaces.length === 0) {
        console.warn('No known faces available for matching');
        return bestMatch;
    }
    
    try {
        // Create array to collect all match results
        let allMatches = [];
        
        for (const knownFace of knownFaces) {
            if (!knownFace.descriptor) {
                console.warn(`Missing descriptor for known face: ${knownFace.name}`);
                continue;
            }
            
            // Ensure descriptors are Float32Array type for consistent comparison
            const faceDescriptorArray = new Float32Array(faceDescriptor);
            
            // Calculate face similarity using Euclidean distance
            const distance = faceapi.euclideanDistance(
                faceDescriptorArray,
                new Float32Array(knownFace.descriptor)
            );
            
            // Convert distance to similarity score (0-1)
            const confidence = 1 - distance;
            
            // Add to all matches for diagnostics
            allMatches.push({
                name: knownFace.name,
                confidence: confidence
            });
            
            // Check against primary threshold
            if (confidence > HIGH_CONFIDENCE_THRESHOLD && confidence > bestMatch.confidence) {
                bestMatch = {
                    isMatch: true,
                    name: knownFace.name,
                    confidence: confidence
                };
            }
        }
        
        // If no match found with high confidence, try medium confidence
        if (!bestMatch.isMatch) {
            for (const match of allMatches) {
                if (match.confidence > MEDIUM_CONFIDENCE_THRESHOLD && 
                    match.confidence > bestMatch.confidence) {
                    bestMatch = {
                        isMatch: true,
                        name: match.name,
                        confidence: match.confidence,
                        isLowerConfidence: true
                    };
                }
            }
        }
        
        return bestMatch;
    } catch (error) {
        console.error('Error in face matching:', error);
        return bestMatch;
    }
}

function debugKnownFaces() {
    console.log(`Total known faces: ${knownFaces.length}`);
    knownFaces.forEach((face, index) => {
        console.log(`Face #${index}: ${face.name}`);
        console.log(`Has valid descriptor: ${face.descriptor && face.descriptor.length > 0}`);
        // Log the first few values of the descriptor to check if it looks valid
        if (face.descriptor) {
            console.log(`Descriptor sample: ${face.descriptor.slice(0, 5).join(', ')}`);
        }
    });
}
        
// Helper function for rounded rectangles
function roundedRect(ctx, x, y, width, height, radius) {
    ctx.beginPath();
    ctx.moveTo(x + radius, y);
    ctx.arcTo(x + width, y, x + width, y + height, radius);
    ctx.arcTo(x + width, y + height, x, y + height, radius);
    ctx.arcTo(x, y + height, x, y, radius);
    ctx.arcTo(x, y, x + width, y, radius);
    ctx.closePath();
    ctx.fill();
}

// And for the path version
function roundedRectPath(ctx, x, y, width, height, radius) {
    ctx.beginPath();
    ctx.moveTo(x + radius, y);
    ctx.arcTo(x + width, y, x + width, y + height, radius);
    ctx.arcTo(x + width, y + height, x, y + height, radius);
    ctx.arcTo(x, y + height, x, y, radius);
    ctx.arcTo(x, y, x + width, y, radius);
}
// Log attendance for a recognized employee
async function logAttendance(employeeName) {
    try {
        const today = new Date();
        const currentTime = today.toLocaleTimeString();
        const currentDate = today.toISOString().split('T')[0];
        
        // First, check if we already have attendance data for this person today
        let existingAttendance = attendanceData[employeeName];
        let isEntry = false;
        let shouldLog = true;
        
        // Get the current attendance status for today
        if (!existingAttendance) {
            // No existing data at all - this is definitely an entry
            isEntry = true;
            attendanceData[employeeName] = {
                name: employeeName,
                date: currentDate,
                entryTime: currentTime,
                exitTime: ''
            };
        } else if (existingAttendance.date === currentDate) {
            // We have data for today - check entry/exit status
            if (existingAttendance.entryTime && !existingAttendance.exitTime) {
                // They entered but didn't exit - so this should be an exit
                // Only log exit if sufficient time has passed (e.g., 30 minutes)
                const entryTimeParts = existingAttendance.entryTime.split(':');
                const entryDate = new Date();
                entryDate.setHours(parseInt(entryTimeParts[0], 10));
                entryDate.setMinutes(parseInt(entryTimeParts[1], 10));
                entryDate.setSeconds(parseInt(entryTimeParts[2], 10));
                
                const timeDiffMinutes = (today - entryDate) / (1000 * 60);
                
                if (timeDiffMinutes >= 5) { // Minimum time between entry and exit (reduced to 5 min for testing)
                    isEntry = false;
                    attendanceData[employeeName].exitTime = currentTime;
                } else {
                    // Too soon for an exit, don't log anything
                    shouldLog = false;
                }
            } else if (existingAttendance.entryTime && existingAttendance.exitTime) {
                // Both entry and exit already logged for today - don't do anything
                shouldLog = false;
                console.log(`${employeeName} already has complete attendance for today`);
            }
        } else {
            // Data exists but for a different date - this is an entry for today
            isEntry = true;
            attendanceData[employeeName] = {
                name: employeeName,
                date: currentDate,
                entryTime: currentTime,
                exitTime: ''
            };
        }
        
        if (shouldLog) {
            // Create attendance record
            const attendanceRecord = {
                name: employeeName,
                date: currentDate,
                entryTime: isEntry ? currentTime : (attendanceData[employeeName]?.entryTime || ''),
                exitTime: isEntry ? '' : currentTime
            };
            
            // Update local tracking object if not already updated
            if (isEntry || !existingAttendance) {
                attendanceData[employeeName] = attendanceRecord;
            }
            
            // Send to backend
            await fetch('/api/log-attendance', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(attendanceRecord)
            });
            
            updateTodayAttendance();
            
            console.log(`Logged ${isEntry ? 'entry' : 'exit'} for ${employeeName} at ${currentTime}`);
            return isEntry; // Return isEntry flag for greeting message
        }
        
        return null; // Nothing logged
    } catch (error) {
        console.error('Error logging attendance:', error);
        return null;
    }
}
        

// Updated speak greeting function
function speakGreeting(name) {
    // Get current entry/exit status from attendance data
    const isEntry = attendanceData[name] && !attendanceData[name].exitTime;
    let greeting;
    
    if (isEntry) {
        // Entry greeting options
        const greetings = [
            `Welcome, ${name}. Your entry has been recorded.`,
            `Hello ${name}! You've been checked in.`,
            `Good day, ${name}. Your arrival has been noted.`
        ];
        greeting = greetings[Math.floor(Math.random() * greetings.length)];
    } else {
        // Exit greeting options
        const greetings = [
            `Goodbye, ${name}. Your exit has been recorded.`,
            `See you tomorrow, ${name}. Your departure has been noted.`,
            `Have a nice day, ${name}. You've been checked out.`
        ];
        greeting = greetings[Math.floor(Math.random() * greetings.length)];
    }
    
    // Use browser's speech synthesis
    if ('speechSynthesis' in window) {
        const utterance = new SpeechSynthesisUtterance(greeting);
        window.speechSynthesis.speak(utterance);
    }
}
        // Update system metrics display
        function updateSystemMetrics() {
            // Update system uptime
            const currentTime = new Date();
            const uptimeHours = Math.floor((currentTime - systemStartTime) / (1000 * 60 * 60));
            systemUptimeElement.textContent = `${uptimeHours}h`;
        }
        
        // Update total employees count
        function updateTotalEmployees() {
            totalEmployeesElement.textContent = knownFaces.length;
        }
        
        // Update today's attendance count
        function updateTodayAttendance() {
            const uniqueAttendees = Object.keys(attendanceData).length;
            todayAttendanceElement.textContent = uniqueAttendees;
        }
        
        // Show toast notification
        function showToast(message, type = 'info') {
            const toast = document.getElementById('toast');
            const toastMessage = document.getElementById('toastMessage');
            
            // Set message
            toastMessage.textContent = message;
            
            // Set type class
            toast.className = 'toast';
            toast.classList.add(type);
            toast.classList.add('show');
            
            // Auto hide after 3 seconds
            setTimeout(() => {
                toast.classList.remove('show');
            }, 3000);
        }
            </script>
</body>
</html>
